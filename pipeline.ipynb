{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from googleapiclient.discovery import build\n",
    "import gspread\n",
    "from httplib2 import Http\n",
    "from oauth2client import file, client, tools\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "import re\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key takeaways\n",
    "\n",
    "* Use American-English right from the beginning\n",
    "* Force the people to be responsible for their stuff\n",
    "* Force the people to work on mendeley\n",
    "* Force the people to use harvard citation\n",
    "* Force the people to write texts with the roughly the same length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does this script work?!\n",
    "\n",
    "* The order of the trends is done by the order of the trends_intro and then by the inner order of the groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "## Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BULLET_ICON = \"\" # e.g. \"•\"\n",
    "\n",
    "# Abbreviations-Section\n",
    "ABBREVIATION_TITLE = \"List of Abbrevations\"\n",
    "ABBREVIATION_HEADLINE_TAG = \"H6\"\n",
    "\n",
    "# Trends-Section\n",
    "TRENDS_TITLE = \"Trends\"\n",
    "TRENDS_DESCRIPTION = \"\"\n",
    "TRENDS_SUB_SECTION_NAMES_LIST_TAG = \"Header-Right\"\n",
    "TRENDS_SUB_SECTION_TITLES_LIST_TAG = \"Table-of-Contents-Trend-Cover-Page\"\n",
    "TRENDS_SUB_SECTION_HEADLINE_TAG = \"H2\"\n",
    "TRENDS_SUB_SECTION_SLOGAN_TAG = \"H3\"\n",
    "TRENDS_SUB_SECTION_AREA_HEADLINE_TAG = \"H4\" # Trend Drivers, Trend Facts ... \n",
    "TRENDS_SUB_SECTION_AREA_IMPACT_HEADLINE = \"Impact on the construction industry\"\n",
    "\n",
    "# Sources-Section\n",
    "SOURCES_TITLE = \"Sources\"\n",
    "SOURCES_DESCRIPTION = \"\"\n",
    "SOURCES_KEY_TAG = \"H6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "This pipeline downloads the data from the googel spread sheet and then replaced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Help functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Text formatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_text(text):\n",
    "    text = text.replace(\"&\", \"&amp;\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_text_test():\n",
    "    print(sanitize_text(\"Hello & World\") == \"Hello &amp; World\")\n",
    "\n",
    "#sanitize_text_test()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_xml_list(text):\n",
    "    result = \"<List>\"\n",
    "    li = [s.strip() for s in text.splitlines()]\n",
    "    for i, l in enumerate(li):\n",
    "        result += \"<List-Element>\" + l+ \"</List-Element>\"\n",
    "        if not (len(li) - 1) == i:\n",
    "            result += \"\\n\"\n",
    "\n",
    "    result += \"</List>\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_xml_list_test():\n",
    "    print(generate_xml_list(\"Hello World \\n hello / Seb \\n hello CDTM\\n\"))\n",
    "    \n",
    "#generate_xml_list_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_remove_duplicates_and_sort_by_last_names(names):\n",
    "    names = set(names)\n",
    "    names = list(names)\n",
    "    names = sorted(sorted(names), key=lambda n: n.split()[1])\n",
    "    names = \", \".join(names)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_remove_duplicates_and_sort_by_last_names_test():\n",
    "    print(stringify_remove_duplicates_and_sort_by_last_names([\"Zoe Lawry\", \"Roxana Salyards\", \"Luella Heide\", \"Cortney Lawry\", \"Luella Heide\"]))\n",
    "    \n",
    "#stringify_remove_duplicates_and_sort_by_last_names_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Find and replace author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_author_and_replace(text):    \n",
    "    counter = 0\n",
    "    authors = dict()\n",
    "    p = re.compile(\"\\[([a-zäöüÄÖÜA-Z_0-9]*)\")\n",
    "    for match in p.finditer(text):\n",
    "        key = match.group(1)\n",
    "        if key not in authors and len(key) > 0:\n",
    "            counter += 1\n",
    "            authors[key] = counter\n",
    "    \n",
    "    # print(authors)\n",
    "            \n",
    "    for key, value in authors.items():\n",
    "        text = text.replace(\"[\"+str(key), \"[\"+str(value))\n",
    "        \n",
    "    return (text, authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_author_and_replace_test():\n",
    "    test = \"The side bar include [] [KRAUZ, p.22] a Cheatsheet, full [KRAUZ] Reference, sults with the Tools below [SEB], [KAYA]. Replace & List outp [HASE]. [KRAUZ] [KRAUZ] [KRAUZ] [KRAUZ]\"\n",
    "    text, authors = find_author_and_replace(test)\n",
    "    #print(text)\n",
    "    #print(authors)\n",
    "\n",
    "    \n",
    "find_author_and_replace_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data from the spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.countingcalculi.com/explanations/google_sheets_and_jupyter_notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If modifying these scopes, delete the file token.json.\n",
    "SCOPES = 'https://www.googleapis.com/auth/spreadsheets.readonly'\n",
    "\n",
    "# The ID and range of a sample spreadsheet.\n",
    "SPREADSHEET_ID = '1pLSRm8pHlTGm-AYuKe4PJGpVxAhr3G_Neu2i8TF-a1I'\n",
    "RANGE_NAME = 'Trends'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_google_sheets():\n",
    "    scope = ['https://www.googleapis.com/auth/spreadsheets.readonly']\n",
    "    credentials = ServiceAccountCredentials.from_json_keyfile_name('./credentials.json', scope)\n",
    "    # print(credentials)\n",
    "    gc = gspread.authorize(credentials)\n",
    "    \n",
    "    book = gc.open_by_key(SPREADSHEET_ID)\n",
    "    return book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Spreadsheet 'TSS2019_TrendSeminar' id:1pLSRm8pHlTGm-AYuKe4PJGpVxAhr3G_Neu2i8TF-a1I>\n"
     ]
    }
   ],
   "source": [
    "book = load_data_from_google_sheets()\n",
    "print(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trends\n",
    "\n",
    "Generate the trends from the sheet and transform it into the XML structure\n",
    "\n",
    "```\n",
    "<Trends-Section>\n",
    "<List>\n",
    "<List-Element>Technology Trends</List-Element>\n",
    "<List-Element>Societal &amp; Environmental Trends</List-Element>\n",
    "</List>\n",
    "<Trends-Sub-Sections>\n",
    "<Trends-Sub-Section>\n",
    "<H1>AI</H1>\n",
    "<H3>SUBRTITLE</H3>\n",
    "<Text>Intro text for bla bla</Text>\n",
    "<Trends>\n",
    "<Trend>\n",
    "<H2>Trend 1 Title</H2>\n",
    "<H3>Slogan</H3>\n",
    "<Text>\n",
    "Intro text\n",
    "<H4>Facts</H4>\n",
    "<List>\n",
    "<List-Element>Hello World</List-Element>\n",
    "<List-Element>Hello CDTM!</List-Element>\n",
    "<List-Element>Hello Sebastian</List-Element>\n",
    "...\n",
    "</List>\n",
    "</Text>\n",
    "</Trend>\n",
    "</Trends>\n",
    "</Trends-Sub-Section>\n",
    "...\n",
    "</Trends-Sub-Sections>\n",
    "\n",
    "\n",
    "<Abbreviation><H6>BIM</H6>Building information modeling</Abbreviation>\n",
    "<Abbreviation><H6>LCC</H6>Life Cycle Costing</Abbreviation>\n",
    "...\n",
    "</Abbreviations>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trends(book):\n",
    "    # Init XML structure\n",
    "    result = \"<Trends-Section>\\n\";\n",
    "    result += \"<H1>\"+TRENDS_TITLE+\"</H1>\\n\";\n",
    "    # Add description if necessary\n",
    "    if len(TRENDS_DESCRIPTION) > 0:\n",
    "        result += \"<Text>\"+TRENDS_DESCRIPTION+\"</Text>\\n\";\n",
    "    \n",
    "    # Init list of trend sections\n",
    "    result_trend_list = \"<List>\\n\"\n",
    "    \n",
    "    # Load trends\n",
    "    # Trends_intro\n",
    "    worksheet = book.worksheet(\"Trend_Intro\")\n",
    "    table = worksheet.get_all_values()\n",
    "    ##Convert table data into a dataframe\n",
    "    df_trends_intro = pd.DataFrame(table[1:], columns=table[0])\n",
    "    # print(df_trends_intro)\n",
    "\n",
    "    worksheet = book.worksheet(\"Trends\")\n",
    "    table = worksheet.get_all_values()\n",
    "    # Convert table data into a dataframe\n",
    "    df_trends = pd.DataFrame(table[2:], columns=table[0])\n",
    "    # print(df_trends)\n",
    "    \n",
    "    # Start with sub sections\n",
    "    result_sub_sections = \"<Trends-Sub-Sections>\\n\"\n",
    "    # Iterate over the trend intro\n",
    "    for index, row in islice(df_trends_intro.iterrows(), 0, None):\n",
    "        \n",
    "        # Trend sub section names\n",
    "        trend_sub_section_names = []\n",
    "        \n",
    "        \n",
    "        # Trend sub section titles\n",
    "        trend_sub_section_titles = []\n",
    "        \n",
    "        # Grab the key and values\n",
    "        key = sanitize_text(row[3])\n",
    "        intro_text = sanitize_text(row[4])\n",
    "        intro_responsible = sanitize_text(row[2])\n",
    "        \n",
    "        # Init the trend sub section\n",
    "        result_trend_sub_section = '<Trends-Sub-Section title=\"'+key+'\">\\n';\n",
    "        \n",
    "        result_trend_sub_section += \"<H1>\"+ key + \"</H1>\\n\"\n",
    "        result_trend_sub_section += '<Text responsible=\"'+intro_responsible+'\">'+ intro_text + \"</Text>\\n\"\n",
    "        \n",
    "        # Add the trend to the overview list\n",
    "        result_trend_list += \"<List-Element>\" + key + \"</List-Element>\\n\"\n",
    "        \n",
    "        # Start adding the trends\n",
    "        result_trend_sub_section += '<Trends>\\n'\n",
    "        \n",
    "        for trend_index, trend_row in df_trends.loc[df_trends['Sub-Section'] == row[3]].iterrows():\n",
    "            trend_title = sanitize_text(trend_row[2])\n",
    "            trend_slogan = sanitize_text(trend_row[7])\n",
    "            trend_intro = sanitize_text(trend_row[9])\n",
    "            trend_facts = sanitize_text(trend_row[11])\n",
    "            trend_drivers = sanitize_text(trend_row[13])\n",
    "            trend_challanges = sanitize_text(trend_row[15])\n",
    "            trend_impact = sanitize_text(trend_row[17])\n",
    "            trend_responsible = sanitize_text(trend_row[5])\n",
    "            \n",
    "            # Add the responsible person its name from each trend to the names list\n",
    "            trend_sub_section_names.append(trend_responsible)\n",
    "            \n",
    "            # Add the trend title to the list of trend titles per trend sub section\n",
    "            trend_sub_section_titles.append(trend_title)\n",
    "            \n",
    "            result_trend = '<Trend responsible=\"'+trend_responsible+'\">'            \n",
    "            \n",
    "            result_trend += \"<\"+TRENDS_SUB_SECTION_HEADLINE_TAG+\">\" + trend_title + \"</\"+TRENDS_SUB_SECTION_HEADLINE_TAG+\">\\n\"\n",
    "            result_trend += \"<\"+TRENDS_SUB_SECTION_SLOGAN_TAG+\">\" + trend_slogan + \"</\"+TRENDS_SUB_SECTION_SLOGAN_TAG+\">\\n\"\n",
    "            result_trend += \"<Text>\"\n",
    "            # Trend intro\n",
    "            result_trend += trend_intro + \"\\n\"\n",
    "            # Trend Facts\n",
    "            result_trend += \"<\"+TRENDS_SUB_SECTION_AREA_HEADLINE_TAG+\">\"+\"Facts:\"+\"</\"+TRENDS_SUB_SECTION_AREA_HEADLINE_TAG+\">\"+\"\\n\"\n",
    "            result_trend += generate_xml_list(trend_facts) +\"\\n\"\n",
    "            # Trend Key Drivers\n",
    "            result_trend += \"<\"+TRENDS_SUB_SECTION_AREA_HEADLINE_TAG+\">\"+\"Key Drivers:\"+\"</\"+TRENDS_SUB_SECTION_AREA_HEADLINE_TAG+\">\"+\"\\n\"\n",
    "            result_trend += generate_xml_list(trend_drivers) +\"\\n\"\n",
    "            # Trend Challenges\n",
    "            result_trend += \"<\"+TRENDS_SUB_SECTION_AREA_HEADLINE_TAG+\">\"+\"Challenges:\"+\"</\"+TRENDS_SUB_SECTION_AREA_HEADLINE_TAG+\">\"+\"\\n\"\n",
    "            result_trend += generate_xml_list(trend_challanges) +\"\\n\"\n",
    "            # Trend Impact Headline\n",
    "            result_trend += \"<\"+TRENDS_SUB_SECTION_AREA_HEADLINE_TAG+\">\"+TRENDS_SUB_SECTION_AREA_IMPACT_HEADLINE +\":\"+\"</\"+TRENDS_SUB_SECTION_AREA_HEADLINE_TAG+\">\"+\"\\n\"\n",
    "            result_trend += \"<Text>\"+trend_impact+\"</Text>\"\n",
    "            # Trend Impact Text\n",
    "            result_trend += \"</Text>\"\n",
    "            result_trend += \"</Trend>\\n\"\n",
    "            result_trend_sub_section += result_trend\n",
    "        \n",
    "        # Close the trend section\n",
    "        result_trend_sub_section += '</Trends>\\n'\n",
    "    \n",
    "        # Generate the string with the names of the trend sub section\n",
    "        trend_sub_section_names = stringify_remove_duplicates_and_sort_by_last_names(trend_sub_section_names)\n",
    "        result_trend_sub_section += \"<Trend-Sub-Section-Names>\"\n",
    "        result_trend_sub_section += \"<\"+TRENDS_SUB_SECTION_NAMES_LIST_TAG+\">\"+trend_sub_section_names+\"</\"+TRENDS_SUB_SECTION_NAMES_LIST_TAG+\">\"\n",
    "        result_trend_sub_section += \"</Trend-Sub-Section-Names>\\n\"\n",
    "        \n",
    "        # Generate the list of titles of the trend sub section\n",
    "        trend_sub_section_titles = \"\\n\".join(trend_sub_section_titles)\n",
    "        result_trend_sub_section += \"<Trend-Sub-Section-Titles>\"\n",
    "        result_trend_sub_section += \"<\"+TRENDS_SUB_SECTION_TITLES_LIST_TAG+\">\"+trend_sub_section_titles+\"</\"+TRENDS_SUB_SECTION_TITLES_LIST_TAG+\">\"\n",
    "        result_trend_sub_section += \"</Trend-Sub-Section-Titles>\\n\"\n",
    "\n",
    "        # Close the trend sub section\n",
    "        result_trend_sub_section += \"</Trends-Sub-Section>\\n\";\n",
    "\n",
    "        # Add it to the result\n",
    "        result_sub_sections += result_trend_sub_section;\n",
    "\n",
    "    result_sub_sections += \"</Trends-Sub-Sections>\"\n",
    "    \n",
    "    result_trend_list += \"</List>\"\n",
    "    \n",
    "    # Add the elements to the result object\n",
    "    result += result_trend_list + \"\\n\"\n",
    "    result += result_sub_sections + \"\\n\"\n",
    "    result += \"</Trends-Section>\\n\";\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenarios\n",
    "\n",
    "Generate scenario XML from excel sheet\n",
    "```\n",
    "<Scenarios>\n",
    "  <Scenario>\n",
    "    <Title>\n",
    "    <H1>shitty title</H1>\n",
    "    </Title>\n",
    "    \n",
    "    <Subtitle>\n",
    "    <H2>shitty subtitle</H2>\n",
    "    </Subtitle>\n",
    "    \n",
    "    <Text>\n",
    "    sometext\n",
    "    </Text>\n",
    "  </Scenario>\n",
    "  <Scenario>\n",
    "      .\n",
    "      .\n",
    "      .\n",
    "  </Scenario>\n",
    "  ...\n",
    "  ...\n",
    "  ...\n",
    "  <Scenario>\n",
    "      .\n",
    "      .\n",
    "      .\n",
    "  </Scenario>\n",
    "</Scenarios>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listify_sign_posts(text):\n",
    "    li = [s.strip() for s in text.splitlines()]\n",
    "    root = etree.Element(\"Sign-Posts\")\n",
    "    for item in li:\n",
    "        if item == \"\" or item == \"\\n\":\n",
    "            continue\n",
    "        post = etree.Element(\"Sign-Post\")\n",
    "        post.text = item\n",
    "        root.append(post)\n",
    "    return root\n",
    "        \n",
    "def generate_scenario_xml(book):\n",
    "    scenariosheet = book.worksheet(\"Scenarios\")\n",
    "    table = scenariosheet.get_all_values()\n",
    "    df_scenarios = pd.DataFrame(table[2:], columns=table[0])\n",
    "    \n",
    "    # Section\n",
    "    scenarios_section = etree.Element(\"Scenarios-Section\")\n",
    "    \n",
    "    # Add headline\n",
    "    h1 = etree.Element(\"H1\")\n",
    "    h1.text = \"Scenarios\"\n",
    "    scenarios_section.append(h1)\n",
    "    \n",
    "    # Add scenarios list\n",
    "    scenarios_list = etree.Element(\"List\")\n",
    "    for index, row in islice(df_scenarios.iterrows(), 0, None):        \n",
    "        scenarios_list_element = etree.Element(\"List-Element\")\n",
    "        scenarios_list_element.text = sanitize_text(row[2])\n",
    "        scenarios_list.append(scenarios_list_element)\n",
    "    \n",
    "    scenarios_section.append(scenarios_list)\n",
    "    \n",
    "    # Build the XML tree\n",
    "    root = etree.Element(\"Scenarios\")\n",
    "    \n",
    "    for index, row in islice(df_scenarios.iterrows(), 0, None):\n",
    "        scenario = etree.Element(\"Scenario\")\n",
    "        \n",
    "        title = etree.Element(\"Title\")\n",
    "        h1 = etree.Element(\"H1\")\n",
    "        h1.text = sanitize_text(row[2])\n",
    "        title.append(h1)\n",
    "        scenario.append(title)\n",
    "        \n",
    "        subtitle = etree.Element(\"Subtitle\")\n",
    "        h2 = etree.Element(\"H2\")\n",
    "        h2.text =  sanitize_text(row[5])\n",
    "        subtitle.append(h2)\n",
    "        scenario.append(subtitle)\n",
    "        \n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = sanitize_text(row[7])\n",
    "        scenario.append(text)\n",
    "        \n",
    "        #sign_posts = etree.Element(\"sign_posts\")\n",
    "        #sign_posts.text = generate_xml_list(sanitize_text(row[9]))\n",
    "        scenario.append(listify_sign_posts(sanitize_text(row[9])))\n",
    "        \n",
    "        root.append(scenario)\n",
    "        \n",
    "        scenarios_section.append(root)\n",
    "        \n",
    "    return etree.tostring(scenarios_section, encoding=\"unicode\", method='xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas\n",
    "\n",
    "Generate Ideas XML from excel sheet\n",
    "```\n",
    "<Ideas>\n",
    "    <Idea>\n",
    "        <Title>\n",
    "            <H1>\n",
    "            </H1>\n",
    "        </Title>\n",
    "        <Subtitle>\n",
    "            <H2>\n",
    "            </H2>\n",
    "        </Subtitle>\n",
    "        <Value-Proposition-Canvas>\n",
    "            <Item>\n",
    "            </Item>\n",
    "            <Item>\n",
    "            </Item>\n",
    "        </Value-Proposition-Canvas>\n",
    "        <Value-Proposition-Text>\n",
    "            <Text>\n",
    "            </Text>\n",
    "        </Value-Proposition-Text>\n",
    "        ...\n",
    "        ...\n",
    "        ...\n",
    "    </Idea>\n",
    "    ...\n",
    "    ...\n",
    "</Ideas>\n",
    "```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listify_canvas(text, root_tag):\n",
    "    li = [s.strip() for s in text.splitlines()]\n",
    "    root = etree.Element(root_tag)\n",
    "    root_list = etree.Element(\"List\")\n",
    "    for item in li:\n",
    "        if item == \"\" or item == \"\\n\":\n",
    "            continue\n",
    "        post = etree.Element(\"List-Element\")\n",
    "        post.text = BULLET_ICON + item\n",
    "        root_list.append(post)\n",
    "    root.append(root_list)\n",
    "    return root\n",
    "\n",
    "def generate_ideas(book):\n",
    "    ideasheet = book.worksheet(\"Ideation\")\n",
    "    table = ideasheet.get_all_values()\n",
    "    df_ideas = pd.DataFrame(table[3:])#, columns=table[3])\n",
    "    #print(df_ideas.head)\n",
    "    #df_ideas.set_index('Title',inplace=True)\n",
    "    df_ideas = df_ideas.transpose()\n",
    "    df_ideas = df_ideas[1:]\n",
    "    #print(df_ideas.shape)#['Title'])\n",
    "    # Build the XML tree\n",
    "    ideas_section = etree.Element(\"Ideas-Section\")\n",
    "    \n",
    "    # Add headline\n",
    "    h1 = etree.Element(\"H1\")\n",
    "    h1.text = \"Ideas\"\n",
    "    ideas_section.append(h1)\n",
    "    \n",
    "    # Add ideas list\n",
    "    ideas_list = etree.Element(\"List\")\n",
    "    for index, row in islice(df_ideas.iterrows(), 0, None):        \n",
    "        ideas_list_element = etree.Element(\"List-Element\")\n",
    "        ideas_list_element.text = row[0]\n",
    "        ideas_list.append(ideas_list_element)\n",
    "    \n",
    "    \n",
    "    ideas_section.append(ideas_list)\n",
    "    \n",
    "    # Ideas\n",
    "    ideas = etree.Element(\"Ideas\")   \n",
    "    \n",
    "    for index, row in islice(df_ideas.iterrows(), 0, None):\n",
    "        if (row[0]) == \"\":\n",
    "            continue\n",
    "        idea = etree.Element(\"Idea\")\n",
    "        \n",
    "        # Title\n",
    "        title = etree.Element(\"Title\")\n",
    "        heading1 = etree.Element(\"H1\")\n",
    "        heading1.text = row[0]\n",
    "        title.append(heading1)\n",
    "        idea.append(title)\n",
    "        \n",
    "        #subtitle\n",
    "        sub = etree.Element(\"Subtitle\")\n",
    "        h2 = etree.Element(\"H2\")\n",
    "        h2.text = row[1]\n",
    "        sub.append(h2)\n",
    "        idea.append(sub)\n",
    "        \n",
    "        #intro\n",
    "        intro = etree.Element(\"Intro\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[2]\n",
    "        intro.append(text)\n",
    "        idea.append(intro)\n",
    "        \n",
    "        #Value Proposition_Canvas\n",
    "        #vpc = etree.Element(\"Value_Proposition_Canvas\")\n",
    "        #text = etree.Element(\"text\")\n",
    "        #text.text = row[4]\n",
    "        #vpc.append(listify_canvas(row[4], \"Value_Proposition_Canvas\"))\n",
    "        idea.append(listify_canvas(row[4], \"Value-Proposition-Canvas\"))\n",
    "        \n",
    "        #Value Proposition_Text\n",
    "        vpt = etree.Element(\"Value-Proposition-Text\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[5]\n",
    "        vpt.append(text)\n",
    "        idea.append(vpt)        \n",
    "        \n",
    "        #Customer Relationships_Canvas\n",
    "        #crc = etree.Element(\"Customer_Relationships_Canvas\")\n",
    "        #text = etree.Element(\"text\")\n",
    "        #text.text = row[6]\n",
    "        #crc.append(text)\n",
    "        idea.append(listify_canvas(row[6], \"Customer-Relationships-Canvas\"))  \n",
    "        \n",
    "        #Customer Relationships_Text\n",
    "        crt = etree.Element(\"Customer-Relationships-Text\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[7]\n",
    "        crt.append(text)\n",
    "        idea.append(crt)  \n",
    "        \n",
    "        #Channels_Canvas\n",
    "        #cc = etree.Element(\"Channels_Canvas\")\n",
    "        #text = etree.Element(\"text\")\n",
    "        #text.text = row[8]\n",
    "        #cc.append(text)\n",
    "        idea.append(listify_canvas(row[8], \"Channels-Canvas\"))\n",
    "        \n",
    "        #Channels_Text\n",
    "        ct = etree.Element(\"Channels-Text\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[9]\n",
    "        ct.append(text)\n",
    "        idea.append(ct)\n",
    "        \n",
    "        #Key Resources_Canvas\n",
    "        #krc = etree.Element(\"Key_Resources_Canvas\")\n",
    "        #text = etree.Element(\"text\")\n",
    "        #text.text = row[10]\n",
    "        #krc.append(text)\n",
    "        idea.append(listify_canvas(row[10], \"Key-Resources-Canvas\"))\n",
    "        \n",
    "        #Key Resources_Text\n",
    "        krt = etree.Element(\"Key-Resources-Text\")\n",
    "        text = etree.Element(\"text\")\n",
    "        text.text = row[11]\n",
    "        krt.append(text)\n",
    "        idea.append(krt)\n",
    "        \n",
    "        #Key Activities_Canvas\n",
    "        #kac = etree.Element(\"Key_Activities_Canvas\")\n",
    "        #text = etree.Element(\"text\")\n",
    "        #text.text = row[12]\n",
    "        #kac.append(text)\n",
    "        idea.append(listify_canvas(row[12], \"Key-Activities-Canvas\"))\n",
    "        \n",
    "        #Key Activities_Text\n",
    "        kat = etree.Element(\"Key-Activities-Text\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[13]\n",
    "        kat.append(text)\n",
    "        idea.append(kat)\n",
    "        \n",
    "        #Revenue Streams_Canvas\n",
    "        #rsc = etree.Element(\"Revenue_Streams_Canvas\")\n",
    "        #text = etree.Element(\"text\")\n",
    "        #text.text = row[14]\n",
    "        #rsc.append(text)\n",
    "        idea.append(listify_canvas(row[14], \"Revenue-Streams-Canvas\"))\n",
    "        \n",
    "        #Revenue Streams_Text\n",
    "        rst = etree.Element(\"Revenue-Streams-Text\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[15]\n",
    "        rst.append(text)\n",
    "        idea.append(rst)\n",
    "        \n",
    "        #Key Partners_Canvas\n",
    "        #kpc = etree.Element(\"Key_Partners_Canvas\")\n",
    "        #text = etree.Element(\"text\")\n",
    "        #text.text = row[16]\n",
    "        #kpc.append(text)\n",
    "        idea.append(listify_canvas(row[16], \"Key-Partners-Canvas\"))\n",
    "        \n",
    "        #Key Partners_Text\n",
    "        kpt = etree.Element(\"Key-Partners-Text\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[17]\n",
    "        kpt.append(text)\n",
    "        idea.append(kpt)\n",
    "        \n",
    "        #Customer Segmentation_Canvas\n",
    "        #csc = etree.Element(\"Customer_Segmentation_Canvas\")\n",
    "        #text = etree.Element(\"text\")\n",
    "        #text.text = row[18]\n",
    "        #csc.append(text)\n",
    "        idea.append(listify_canvas(row[18], \"Customer-Segmentation-Canvas\"))\n",
    "        \n",
    "        #Customer Segmentation_Text\n",
    "        cst = etree.Element(\"Customer-Segmentation-Text\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[19]\n",
    "        cst.append(text)\n",
    "        idea.append(cst)\n",
    "        \n",
    "        #Cost Structure_Canvas\n",
    "        #csc = etree.Element(\"Cost Structure_Canvas\")\n",
    "        #text = etree.Element(\"text\")\n",
    "        #text.text = row[20]\n",
    "        #csc.append(text)\n",
    "        idea.append(listify_canvas(row[20], \"Cost-Structure-Canvas\"))\n",
    "        \n",
    "        #Cost Structure_Text\n",
    "        cst = etree.Element(\"Cost-Structure-Text\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[21]\n",
    "        cst.append(text)\n",
    "        idea.append(cst)\n",
    "        \n",
    "        #Senario Fit_1\n",
    "        sf = etree.Element(\"Senario-Fit-1\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[23]\n",
    "        sf.append(text)\n",
    "        idea.append(sf)\n",
    "        \n",
    "        #Senario Fit_2\n",
    "        sf = etree.Element(\"Senario-Fit-2\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[24]\n",
    "        sf.append(text)\n",
    "        idea.append(sf)\n",
    "        \n",
    "        #Senario Fit_3\n",
    "        sf = etree.Element(\"Senario-Fit-3\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[25]\n",
    "        sf.append(text)\n",
    "        idea.append(sf)\n",
    "        \n",
    "        #Senario Fit_4\n",
    "        sf = etree.Element(\"Senario-Fit-4\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[26]\n",
    "        sf.append(text)\n",
    "        idea.append(sf)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ideas.append(idea)\n",
    "        # print(row[0])\n",
    "        \n",
    "        ideas_section.append(ideas)\n",
    "        \n",
    "    return etree.tostring(ideas_section, encoding=\"unicode\", method='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(generate_abbrevations(book))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abbrevations\n",
    "\n",
    "Generate the abbrevations from the sheet and transform it into the XML structure\n",
    "\n",
    "```\n",
    "<Abbreviations>\n",
    "<Abbreviation><H6>AI</H6>Artificial Intelligence</Abbreviation>\n",
    "<Abbreviation><H6>BIM</H6>Building information modeling</Abbreviation>\n",
    "<Abbreviation><H6>LCC</H6>Life Cycle Costing</Abbreviation>\n",
    "...\n",
    "</Abbreviations>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_abbrevations(book):\n",
    "    worksheet = book.worksheet(\"Abreviations\")\n",
    "    table = worksheet.get_all_values()\n",
    "    ##Convert table data into a dataframe\n",
    "    df = pd.DataFrame(table[1:], columns=table[0])\n",
    "    # Init XML structure\n",
    "    result = \"<Abbreviations-Section>\\n\";\n",
    "    result += \"<H1>\"+ABBREVIATION_TITLE+\"</H1>\\n\";\n",
    "    result += \"<Abbreviations>\\n\";\n",
    "    # Iterate over the rows\n",
    "    for index, row in islice(df.iterrows(), 1, None):\n",
    "        # Grab the key and values\n",
    "        key = sanitize_text(row[0])\n",
    "        val = sanitize_text(row[1])\n",
    "        # Create a xml string\n",
    "        result += \"<Abbreviation><\"+ABBREVIATION_HEADLINE_TAG+\">\" + key + \"</\"+ABBREVIATION_HEADLINE_TAG+\">\" + val + \"</Abbreviation>\\n\"\n",
    "    # Add closing tag\n",
    "    result += \"</Abbreviations>\\n\";\n",
    "    result += \"</Abbreviations-Section>\\n\";\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "Generate the sources from the sheet and transform it into the XML structure.\n",
    "Order the sources by the apperance.\n",
    "\n",
    "```\n",
    "<Sources-Section>\n",
    "<H1>Source</H1>\n",
    "<Sources>\n",
    "<Source>\n",
    "<H6>1</H6> Sebastians Report 2017 ....\n",
    "</Source>\n",
    "...\n",
    "</Sources>\n",
    "</Sources-Section>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sources(book, map_hash_source):\n",
    "    errors = []\n",
    "    # invert the mapping NUMBER -> HASH\n",
    "    map_number_hash = {v: k for k, v in map_hash_source.items()}\n",
    "    \n",
    "    # Init an array with the size of the sources\n",
    "    sources = [(\"\",\"\")]*len(map_hash_source)\n",
    "       \n",
    "    worksheet = book.worksheet(\"Sources\")\n",
    "    table = worksheet.get_all_values()\n",
    "    # Convert table data into a dataframe\n",
    "    df = pd.DataFrame(table[1:], columns=table[0])\n",
    "    # print(df_trends)\n",
    "    \n",
    "    # Start with sub sections\n",
    "    result = \"<Sources-Sections>\\n\"\n",
    "    result += \"<H1>\"+SOURCES_TITLE+\"</H1>\\n\"\n",
    "    result += \"<Text>\"+SOURCES_DESCRIPTION+\"</Text>\\n\"\n",
    "    # Start with the list\n",
    "    result += \"<Sources>\\n\"\n",
    "    # Iterate over the sources array\n",
    "    for index, row in islice(df.iterrows(), 1, None):\n",
    "        key = sanitize_text(row[0])\n",
    "        responsible = sanitize_text(row[2])\n",
    "        val = sanitize_text(row[4])\n",
    "        if key in map_hash_source:\n",
    "            # Find the number of the source\n",
    "            source_index = map_hash_source[key]-1\n",
    "            # Add the value of the source to the right order of the array\n",
    "            sources[source_index] = (val, responsible)\n",
    "        else:\n",
    "            err = {\n",
    "                \"type\": \"Source not used\",\n",
    "                \"responsible\": responsible,\n",
    "                \"key\": key,\n",
    "            }\n",
    "            errors.append(err)\n",
    "        \n",
    "    # Iterate of the ordered source array and genrate the xml\n",
    "    for index, (source, responsible) in enumerate(sources):\n",
    "        if (len(source) == 0):\n",
    "            err = {\n",
    "                \"type\": \"Source not declared\",\n",
    "                \"responsible\": \"\",\n",
    "                \"key\": map_number_hash[index+1],\n",
    "            }\n",
    "            errors.append(err)\n",
    "        else:\n",
    "            result += '<Source responsible=\"'+responsible+'\">\\n'\n",
    "            result += \"<\" + SOURCES_KEY_TAG + \">\" + str(index+1) + \"</\" + SOURCES_KEY_TAG + \"> \"\n",
    "            result += source\n",
    "            result += \"\\n\"\n",
    "            result += \"</Source>\\n\"\n",
    "    \n",
    "    # Close the xml tags\n",
    "    result += \"</Sources>\\n\"    \n",
    "    result += \"</Sources-Sections>\\n\"\n",
    "    \n",
    "    return result, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_xml(xml):\n",
    "    xml = xml.replace(\"<List-Element></List-Element>\",\"\") # remove empty lists\n",
    "    xml = xml.replace(\"&#13;\",\"\") # remove some crazy unicode space\n",
    "    return xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    book = load_data_from_google_sheets()\n",
    "    xml = \"\"\n",
    "    # Add Abbreviations\n",
    "    xml += generate_abbrevations(book)\n",
    "    # Add Trends\n",
    "    xml += generate_trends(book)\n",
    "    # Add Scenarios\n",
    "    xml += generate_scenario_xml(book)\n",
    "    # Add Ideation\n",
    "    xml += generate_ideas(book)\n",
    "    # Add Sources    \n",
    "    # Replace the citation\n",
    "    xml, authors = find_author_and_replace(xml)\n",
    "    print(authors)\n",
    "    sources, errors = generate_sources(book, authors)\n",
    "    xml += sources\n",
    "    # Wrap the root object arround all\n",
    "    xml = '<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\\n<Root>\\n' + xml + '</Root>'\n",
    "    \n",
    "    xml = clean_xml(xml)\n",
    "    # print(xml)\n",
    "    return xml, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_data_from_google_sheets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d8a70a266488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-3c7b1d592a44>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_from_google_sheets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mxml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Add Abbreviations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mxml\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgenerate_abbrevations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_data_from_google_sheets' is not defined"
     ]
    }
   ],
   "source": [
    "xml, err = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5e66def1d425>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xml' is not defined"
     ]
    }
   ],
   "source": [
    "xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
